{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd07db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import glob\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90f15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [plt.imread(image) for image in glob.glob('test_images/*.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7a3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Calibrating Camera\n",
      "Camera successfully calibrated.\n"
     ]
    }
   ],
   "source": [
    "def calibrate_camera():\n",
    "    \"\"\"\n",
    "        Calibrate camera from the provided calibration images\n",
    "    \"\"\"\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    \n",
    "    print(\"Starting Calibrating Camera\")\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Apply findChessboardCorners to the individual images\n",
    "    for fname in images:    \n",
    "        img = mpimg.imread(fname)\n",
    "        image_shape = img.shape\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    # Camera calibration, given object points, image points, and the shape of the grayscale image\n",
    "    if (len(objpoints) > 0):\n",
    "        # Camera successfully calibrated.\n",
    "        print(\"Camera successfully calibrated.\")\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_shape[:2], None, None)\n",
    "    else:\n",
    "        # Unable to calibrate the camera.\n",
    "        print(\"Unable to calibrate the camera.\")\n",
    "        ret, mtx, dist, rvecs, tvecs = (None, None, None, None, None)\n",
    "\n",
    "    return mtx, dist\n",
    "\n",
    "mtx, dist = calibrate_camera()\n",
    "    \n",
    "def undistort(image):\n",
    "    \"\"\"\n",
    "        Remove the distortion of an image \n",
    "    \"\"\"\n",
    "    return cv2.undistort(image, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "428f48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, cmap=None):\n",
    "    \"\"\"\n",
    "      show list of images  \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(40,40))    \n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(math.ceil(len(images) / 2), 2, i+1)\n",
    "        plt.imshow(image, cmap)\n",
    "        plt.autoscale(tight=True)\n",
    "    plt.show()\n",
    "    \n",
    "# show_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb841803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(fun, images):\n",
    "    \"\"\"\n",
    "        apply function to list of images\n",
    "    \"\"\"\n",
    "    return list(map(fun, images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c472f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hls(image):\n",
    "    \"\"\"\n",
    "        Convert RGB image to HLS\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "def convert_to_gray(image):\n",
    "    \"\"\"\n",
    "        Convert RGB image to grayscale\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def convert_to_rgp(image):\n",
    "    \"\"\"\n",
    "        Convert RGB image to grayscale\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "gray_images = apply(convert_to_gray, test_images)\n",
    "# show_images(gray_images, \"gray\")\n",
    "hls_images = apply(convert_to_hls, test_images)\n",
    "# show_images(hls_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4144c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_color_threshold(image):\n",
    "    \"\"\"\n",
    "        Extract yellow and white colors from image\n",
    "    \"\"\"\n",
    "    # Convert the input image to HLS\n",
    "    converted_image = convert_to_hls(image)\n",
    "    \n",
    "    # White color mask\n",
    "    lower_threshold = np.uint8([0, 190, 0])\n",
    "    upper_threshold = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    # Yellow color mask\n",
    "    lower_threshold = np.uint8([10, 0, 90])\n",
    "    upper_threshold = np.uint8([50, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "    # Combine white and yellow masks\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return masked_image\n",
    "\n",
    "hls_color_threshold_images = apply(hls_color_threshold, test_images)\n",
    "# show_images(hls_color_threshold_images, \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2b3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_thresholds(image):\n",
    "    \"\"\"\n",
    "        apply all the thresholds on image\n",
    "    \"\"\"\n",
    "    hls = hls_color_threshold(image)\n",
    "    gray = hls[:, :, 1]\n",
    "    s_channel = hls[:, :, 2]\n",
    "    \n",
    "    sobel_binary = np.zeros(shape=gray.shape, dtype=bool)\n",
    "    s_binary = sobel_binary\n",
    "    combined_binary = s_binary.astype(np.float32)\n",
    "\n",
    "    # Sobel Transform\n",
    "    sobel_kernel=7 \n",
    "    mag_thresh=(3, 255)\n",
    "    s_thresh=(170, 255)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = 0 #cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    sobel_abs = np.abs(sobelx**2 + sobely**2)\n",
    "    sobel_abs = np.uint8(255 * sobel_abs / np.max(sobel_abs))\n",
    "\n",
    "    sobel_binary[(sobel_abs > mag_thresh[0]) & (sobel_abs <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "\n",
    "    combined_binary[(s_binary == 1) | (sobel_binary == 1)] = 1\n",
    "    combined_binary = np.uint8(255 * combined_binary / np.max(combined_binary))\n",
    "    \n",
    "    return combined_binary\n",
    "\n",
    "threshold_images = apply(apply_thresholds, test_images)\n",
    "# show_images(threshold_images, \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63c207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region_of_interest(image):\n",
    "    x = int(image.shape[1])\n",
    "    y = int(image.shape[0])\n",
    "    shape = np.array([[0, y], [x, y], [int(0.55 * x), int(0.6 * y)], [int(0.45 * x), int(0.6 * y)]])\n",
    "\n",
    "    # define a numpy array with the dimensions of image, but comprised of zeros\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # Uses 3 channels or 1 channel for color depending on input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    # creates a polygon with the mask color\n",
    "    cv2.fillPoly(mask, np.int32([shape]), ignore_mask_color)\n",
    "\n",
    "    # returns the image only where the mask pixels are not zero\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image\n",
    "\n",
    "roi_images = apply(extract_region_of_interest, threshold_images)\n",
    "# show_images(roi_images, \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c2fff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp(img):\n",
    "    # Vertices extracted manually for performing a perspective transform\n",
    "    bottom_left = [220,720]\n",
    "    bottom_right = [1110, 720]\n",
    "    top_left = [570, 470]\n",
    "    top_right = [722, 470]\n",
    "\n",
    "    source = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "\n",
    "    pts = np.array([bottom_left,bottom_right,top_right,top_left], np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    copy = img.copy()\n",
    "    cv2.polylines(copy,[pts],True,(255,0,0), thickness=3)\n",
    "\n",
    "    # Destination points are chosen such that straight lanes appear more or less parallel in the transformed image.\n",
    "    bottom_left = [320,720]\n",
    "    bottom_right = [920, 720]\n",
    "    top_left = [320, 1]\n",
    "    top_right = [920, 1]\n",
    "\n",
    "    dst = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "    M = cv2.getPerspectiveTransform(source, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, source)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    warped = cv2.warpPerspective(img, M, img_size , flags=cv2.INTER_LINEAR)\n",
    "    return warped, M_inv\n",
    "        \n",
    "warped_images = apply(warp, roi_images)\n",
    "warped_images = [warped_image[0] for warped_image in warped_images]\n",
    "# show_images(warped_images, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
